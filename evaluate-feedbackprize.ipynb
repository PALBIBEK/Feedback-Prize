{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30bc0ed",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:23.397288Z",
     "iopub.status.busy": "2025-03-10T13:28:23.396980Z",
     "iopub.status.idle": "2025-03-10T13:28:24.093971Z",
     "shell.execute_reply": "2025-03-10T13:28:24.093016Z"
    },
    "papermill": {
     "duration": 0.704045,
     "end_time": "2025-03-10T13:28:24.095380",
     "exception": false,
     "start_time": "2025-03-10T13:28:23.391335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv\n",
      "/kaggle/input/feedback-prize-english-language-learning/train.csv\n",
      "/kaggle/input/feedback-prize-english-language-learning/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6763fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:24.105236Z",
     "iopub.status.busy": "2025-03-10T13:28:24.104878Z",
     "iopub.status.idle": "2025-03-10T13:28:33.754235Z",
     "shell.execute_reply": "2025-03-10T13:28:33.753376Z"
    },
    "papermill": {
     "duration": 9.655986,
     "end_time": "2025-03-10T13:28:33.756048",
     "exception": false,
     "start_time": "2025-03-10T13:28:24.100062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228201c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:33.766115Z",
     "iopub.status.busy": "2025-03-10T13:28:33.765647Z",
     "iopub.status.idle": "2025-03-10T13:28:33.962700Z",
     "shell.execute_reply": "2025-03-10T13:28:33.961605Z"
    },
    "papermill": {
     "duration": 0.203725,
     "end_time": "2025-03-10T13:28:33.964373",
     "exception": false,
     "start_time": "2025-03-10T13:28:33.760648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 10 13:28:33 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   34C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be50cd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:33.974531Z",
     "iopub.status.busy": "2025-03-10T13:28:33.974236Z",
     "iopub.status.idle": "2025-03-10T13:28:33.977867Z",
     "shell.execute_reply": "2025-03-10T13:28:33.977230Z"
    },
    "papermill": {
     "duration": 0.009954,
     "end_time": "2025-03-10T13:28:33.979047",
     "exception": false,
     "start_time": "2025-03-10T13:28:33.969093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir=\"/kaggle/working/\"\n",
    "df_training_path=\"../input/feedback-prize-english-language-learning/train.csv\"\n",
    "df_test_path=\"../input/feedback-prize-english-language-learning/train.csv\"\n",
    "sample_submission_path=\"../input/feedback-prize-english-language-learning/sample_submission.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f8cdae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:33.988209Z",
     "iopub.status.busy": "2025-03-10T13:28:33.988000Z",
     "iopub.status.idle": "2025-03-10T13:28:33.991118Z",
     "shell.execute_reply": "2025-03-10T13:28:33.990498Z"
    },
    "papermill": {
     "duration": 0.008927,
     "end_time": "2025-03-10T13:28:33.992240",
     "exception": false,
     "start_time": "2025-03-10T13:28:33.983313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config={}\n",
    "config['base_dir']=base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586eef3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:34.001501Z",
     "iopub.status.busy": "2025-03-10T13:28:34.001231Z",
     "iopub.status.idle": "2025-03-10T13:28:34.172661Z",
     "shell.execute_reply": "2025-03-10T13:28:34.171969Z"
    },
    "papermill": {
     "duration": 0.177711,
     "end_time": "2025-03-10T13:28:34.174197",
     "exception": false,
     "start_time": "2025-03-10T13:28:33.996486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(df_training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e1c743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:34.184099Z",
     "iopub.status.busy": "2025-03-10T13:28:34.183869Z",
     "iopub.status.idle": "2025-03-10T13:28:34.208943Z",
     "shell.execute_reply": "2025-03-10T13:28:34.208223Z"
    },
    "papermill": {
     "duration": 0.031005,
     "end_time": "2025-03-10T13:28:34.210054",
     "exception": false,
     "start_time": "2025-03-10T13:28:34.179049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4f765f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:34.219754Z",
     "iopub.status.busy": "2025-03-10T13:28:34.219485Z",
     "iopub.status.idle": "2025-03-10T13:28:34.245028Z",
     "shell.execute_reply": "2025-03-10T13:28:34.244440Z"
    },
    "papermill": {
     "duration": 0.031728,
     "end_time": "2025-03-10T13:28:34.246245",
     "exception": false,
     "start_time": "2025-03-10T13:28:34.214517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['cohesion'])\n",
    "train_df=train_df.reset_index(drop=True)\n",
    "val_df=val_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b2fb871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:34.255514Z",
     "iopub.status.busy": "2025-03-10T13:28:34.255239Z",
     "iopub.status.idle": "2025-03-10T13:28:34.266314Z",
     "shell.execute_reply": "2025-03-10T13:28:34.265445Z"
    },
    "papermill": {
     "duration": 0.017025,
     "end_time": "2025-03-10T13:28:34.267617",
     "exception": false,
     "start_time": "2025-03-10T13:28:34.250592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F6DEF203DCD1</td>\n",
       "      <td>First impressions is what the person show you....</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4F75DF4CEBE9</td>\n",
       "      <td>This topic brings in a lot of question and con...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F069420C6DB7</td>\n",
       "      <td>Some schools are offering distance learning fo...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E897534557AF</td>\n",
       "      <td>Recently technology have been a great impact i...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83F57096AF9C</td>\n",
       "      <td>Be a master in any area is something really aw...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  F6DEF203DCD1  First impressions is what the person show you....       3.5   \n",
       "1  4F75DF4CEBE9  This topic brings in a lot of question and con...       2.5   \n",
       "2  F069420C6DB7  Some schools are offering distance learning fo...       3.5   \n",
       "3  E897534557AF  Recently technology have been a great impact i...       2.5   \n",
       "4  83F57096AF9C  Be a master in any area is something really aw...       3.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.5          3.0      3.0          2.5  \n",
       "1     3.0         3.0          2.0      2.0          2.5  \n",
       "2     3.0         3.0          3.5      4.0          3.0  \n",
       "3     3.0         3.0          3.0      3.0          2.5  \n",
       "4     3.0         3.5          3.0      2.5          3.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67629e64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T13:28:34.277087Z",
     "iopub.status.busy": "2025-03-10T13:28:34.276888Z",
     "iopub.status.idle": "2025-03-10T13:29:38.447876Z",
     "shell.execute_reply": "2025-03-10T13:29:38.446209Z"
    },
    "papermill": {
     "duration": 64.182,
     "end_time": "2025-03-10T13:29:38.454115",
     "exception": true,
     "start_time": "2025-03-10T13:28:34.272115",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['tokenizer']=AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "def tokenize(df):\n",
    "\n",
    "    text=df[\"full_text\"]\n",
    "\n",
    "    tokenized=tokenizer(text,add_special_tokens=True,max_length=512,padding=True,truncation=True)\n",
    "    tokenized[\"label\"]=[df[i] for i in config[\"tcols\"]]\n",
    "    tokenized[\"length\"]=len(tokenized[\"input_ids\"])\n",
    "\n",
    "    return tokenized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61bafb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:32.549123Z",
     "iopub.status.busy": "2025-03-10T11:15:32.548638Z",
     "iopub.status.idle": "2025-03-10T11:15:32.632092Z",
     "shell.execute_reply": "2025-03-10T11:15:32.631438Z",
     "shell.execute_reply.started": "2025-03-10T11:15:32.549086Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(df_test_path)\n",
    "config['tcols']=[col for col in df.columns if col not in ['text_id','full_text']]\n",
    "print(config['tcols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053ca79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:32.633175Z",
     "iopub.status.busy": "2025-03-10T11:15:32.632963Z",
     "iopub.status.idle": "2025-03-10T11:15:32.643635Z",
     "shell.execute_reply": "2025-03-10T11:15:32.642753Z",
     "shell.execute_reply.started": "2025-03-10T11:15:32.633157Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test[config[\"tcols\"]]=0\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7871433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:32.644694Z",
     "iopub.status.busy": "2025-03-10T11:15:32.644470Z",
     "iopub.status.idle": "2025-03-10T11:15:33.696240Z",
     "shell.execute_reply": "2025-03-10T11:15:33.695261Z",
     "shell.execute_reply.started": "2025-03-10T11:15:32.644676Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds=Dataset.from_pandas(df_test)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd005ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.698755Z",
     "iopub.status.busy": "2025-03-10T11:15:33.697850Z",
     "iopub.status.idle": "2025-03-10T11:15:33.704731Z",
     "shell.execute_reply": "2025-03-10T11:15:33.703764Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.698711Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MeanPooling:\n",
    "    def meanpooling(self,last_hidden_state,attention_mask):\n",
    "        attention_mask=attention_mask.unsqueeze(-1).expand_as(last_hidden_state)\n",
    "        pooled=torch.sum(attention_mask*last_hidden_state,dim=1)\n",
    "        token_count=torch.sum(attention_mask,dim=1)\n",
    "        token_count=torch.clamp(token_count,min=1e-5)\n",
    "        pooled=pooled/token_count\n",
    "        return pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a0cb0e",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.705851Z",
     "iopub.status.busy": "2025-03-10T11:15:33.705565Z",
     "iopub.status.idle": "2025-03-10T11:15:33.769596Z",
     "shell.execute_reply": "2025-03-10T11:15:33.768758Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.705830Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['max_length']=512\n",
    "config['device']=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ec46b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.770848Z",
     "iopub.status.busy": "2025-03-10T11:15:33.770583Z",
     "iopub.status.idle": "2025-03-10T11:15:33.785962Z",
     "shell.execute_reply": "2025-03-10T11:15:33.785088Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.770788Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def prepare_input(text):\n",
    "    if not isinstance(text, str):  # Ensure text is a string\n",
    "        raise ValueError(f\"Expected to get a string, but got {type(text)}\")\n",
    "    \n",
    "    inputs = config['tokenizer'].encode_plus(\n",
    "        text, \n",
    "        return_tensors=None, \n",
    "        add_special_tokens=True, \n",
    "        max_length=config['max_length'],\n",
    "        padding='max_length',  # Use 'padding' instead of 'pad_to_max_length'\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    return {k: torch.tensor(v, dtype=torch.long) for k, v in inputs.items()}\n",
    "\n",
    "\n",
    "class FeedbackPrizeDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.texts = df['full_text'].values\n",
    "        self.labels = df[config[\"tcols\"]].values  # Fixed missing bracket\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item])  # Removed self.cfg\n",
    "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "        return {**inputs, \"label\":label}\n",
    "    \n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db5c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.787057Z",
     "iopub.status.busy": "2025-03-10T11:15:33.786817Z",
     "iopub.status.idle": "2025-03-10T11:15:33.804766Z",
     "shell.execute_reply": "2025-03-10T11:15:33.804115Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.787032Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['encoder_lr']=1e-5\n",
    "config['decoder_lr']=1e-9\n",
    "config['weight_decay']=1e-4\n",
    "config['batch_size']=8\n",
    "config['n_accumulation']=1\n",
    "config['epochs']=1\n",
    "config['train_bs']=3\n",
    "config['test_bs']=3\n",
    "config['lr']=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118c9c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.805890Z",
     "iopub.status.busy": "2025-03-10T11:15:33.805616Z",
     "iopub.status.idle": "2025-03-10T11:15:33.821028Z",
     "shell.execute_reply": "2025-03-10T11:15:33.820220Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.805863Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DebertaModel(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        # self.config=config\n",
    "\n",
    "        self.model_config=AutoConfig.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "        self.config=config\n",
    "        \n",
    "        update_config={\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": 0.,\n",
    "                \"add_pooling_layer\": False,\n",
    "                \"attention_probs_dropout_prob\":0,\n",
    "            }\n",
    "\n",
    "        for key,val in update_config.items():\n",
    "            if hasattr(self.model_config,key):\n",
    "                setattr(self.model_config,key,val)\n",
    "\n",
    "        self.model=AutoModel.from_pretrained(\"microsoft/deberta-v3-large\",config=self.model_config)\n",
    "        self.layernorm=nn.LayerNorm(self.model.config.hidden_size*2)\n",
    "        self.out=nn.Linear(self.model.config.hidden_size*2,len(config[\"tcols\"]))\n",
    "\n",
    "        self.layer_weight=nn.Parameter(torch.zeros(self.model_config.num_hidden_layers).view(self.model_config.num_hidden_layers,1,1,1))\n",
    "\n",
    "        self.dropout=nn.ModuleList(\n",
    "            [nn.Dropout(p=i*0.2) for i in range(5)]\n",
    "        )\n",
    "\n",
    "        self.loss=nn.SmoothL1Loss(reduction='mean')\n",
    "\n",
    "    def forward(self,input_ids,attention_mask):\n",
    "\n",
    "        output=self.model(input_ids,attention_mask)\n",
    "        hidden_outputs=output.hidden_states\n",
    "\n",
    "        hidden_states= torch.stack(tuple(hidden_outputs[-i-1] for i in range(len(hidden_outputs)-1)),dim=0)\n",
    "\n",
    "        layer_weight=F.softmax(self.layer_weight,dim=0)\n",
    "\n",
    "        output_mean=torch.mean(layer_weight*hidden_states,dim=0)\n",
    "\n",
    "        output_max,_=torch.max(hidden_states,dim=0)\n",
    "\n",
    "        output=torch.cat((output_mean,output_max),dim=-1)\n",
    "\n",
    "        output=output[:,0,:]\n",
    "\n",
    "        logits=None\n",
    "        \n",
    "        for i ,dropout in enumerate(self.dropout):\n",
    "            if i==0:\n",
    "                logits=dropout(self.out(output))\n",
    "            else:\n",
    "                logits+=dropout(self.out(output))\n",
    "            \n",
    "        return logits/len(self.dropout)\n",
    "\n",
    "    def get_optimizer_params(self,model,encoder_lr,decoder_lr,weight_decay):\n",
    "\n",
    "\n",
    "        no_decay_list=[\"bias\",\"LayerNorm.weight\"]\n",
    "        optimizer_groups=[\n",
    "            {\n",
    "                'params':[p for n,p in model.model.named_parameters() if not any( nd in n for nd in no_decay_list)],\n",
    "                'lr':encoder_lr,\n",
    "                'weight_decay': weight_decay\n",
    "            },\n",
    "            {\n",
    "                'params':[p for n,p in model.model.named_parameters() if any( nd in n for nd in no_decay_list)],\n",
    "                'lr':encoder_lr,\n",
    "                'weight_decay':0.0\n",
    "            },\n",
    "            {\n",
    "                'params':[p for n,p in model.named_parameters() if \"model\" not in n],\n",
    "                'lr':decoder_lr,\n",
    "                'weight_decay':weight_decay\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return optimizer_groups\n",
    "\n",
    "    def configure_optimizer(self):\n",
    "\n",
    "        parameter_groups=self.get_optimizer_params(self,self.config['encoder_lr'],self.config['decoder_lr']\n",
    "                                                  ,weight_decay=self.config['weight_decay'])\n",
    "\n",
    "        optimizer=torch.optim.AdamW(parameter_groups,lr=self.config['lr'])\n",
    "\n",
    "        warmup_steps=0.09*self.config['data_len']//self.config['batch_size']\n",
    "        training_steps=self.config['epochs']*self.config['data_len']//self.config['batch_size']\n",
    "\n",
    "        scheduler=get_polynomial_decay_schedule_with_warmup(optimizer,warmup_steps,training_steps,lr_end=7e-7, power=3.0)\n",
    "\n",
    "        lr_scheduler_config={\n",
    "            'scheduler':scheduler,\n",
    "            'interval':'step',\n",
    "            'frequency':1,\n",
    "        }\n",
    "\n",
    "        return {'optimizer':optimizer,'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3822ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.822062Z",
     "iopub.status.busy": "2025-03-10T11:15:33.821771Z",
     "iopub.status.idle": "2025-03-10T11:15:33.839204Z",
     "shell.execute_reply": "2025-03-10T11:15:33.838519Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.822034Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def criterion(output,label):\n",
    "    return nn.SmoothL1Loss(reduction='mean')(output,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55aaa22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.841848Z",
     "iopub.status.busy": "2025-03-10T11:15:33.841659Z",
     "iopub.status.idle": "2025-03-10T11:15:33.855615Z",
     "shell.execute_reply": "2025-03-10T11:15:33.854917Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.841832Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader,model,optimizer,scheduler,device,mode):\n",
    "\n",
    "    running_loss=0\n",
    "    average_loss=0\n",
    "    total_len=0\n",
    "\n",
    "    if mode=='train':\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "    \n",
    "    for step,data in enumerate(tqdm(dataloader)):\n",
    "        \n",
    "        input_ids,attention_mask=data['input_ids'].to(device=device),data['attention_mask'].to(device=device)\n",
    "        \n",
    "        output=model(input_ids,attention_mask)\n",
    "\n",
    "        batch_size=input_ids.size()[0]\n",
    "\n",
    "        loss=criterion(output,data['label'].to(device=device))\n",
    "        \n",
    "        if mode=='train':\n",
    "            loss.backward()\n",
    "            \n",
    "            if (step+1)%config['n_accumulation']==0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "\n",
    "        running_loss+=loss.item()*batch_size\n",
    "        total_len+=batch_size\n",
    "        \n",
    "    average_loss=running_loss/total_len\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0bf7d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.856893Z",
     "iopub.status.busy": "2025-03-10T11:15:33.856657Z",
     "iopub.status.idle": "2025-03-10T11:15:33.874726Z",
     "shell.execute_reply": "2025-03-10T11:15:33.873929Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.856875Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(config,train_df,val_df):\n",
    "\n",
    "    train_dataset=FeedbackPrizeDataset(train_df)\n",
    "    val_dataset=FeedbackPrizeDataset(val_df)\n",
    "\n",
    "    train_loader=DataLoader(train_dataset,batch_size=config['train_bs'],shuffle=True)\n",
    "    val_loader=DataLoader(val_dataset,batch_size=config['train_bs'],shuffle=True)\n",
    "\n",
    "    config['data_len']=len(train_loader)\n",
    "\n",
    "    model=DebertaModel(config).to(config['device'])\n",
    "    optimizer_dict=model.configure_optimizer()\n",
    "    optimizer=optimizer_dict['optimizer']\n",
    "    lr_scheduler=optimizer_dict['lr_scheduler']\n",
    "\n",
    "    best_loss=float(\"inf\")\n",
    "    best_model=model.state_dict()\n",
    "    best_optimizer_state=optimizer.state_dict()\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss=train_one_epoch(train_loader,model,optimizer,lr_scheduler,config['device'],mode='train')\n",
    "        val_loss=train_one_epoch(val_loader,model,optimizer,lr_scheduler,config['device'],mode='val')\n",
    "        if val_loss<best_loss:\n",
    "            print(f\"Loss has improved from {best_loss} to {val_loss} in the epoch:{epoch}\")\n",
    "            best_loss=val_loss\n",
    "            best_model=model.state_dict()\n",
    "            best_optimizer_state=optimizer.state_dict()\n",
    "            \n",
    "    return best_loss,best_model,best_optimizer_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96b14f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.875826Z",
     "iopub.status.busy": "2025-03-10T11:15:33.875554Z",
     "iopub.status.idle": "2025-03-10T11:15:33.891308Z",
     "shell.execute_reply": "2025-03-10T11:15:33.890562Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.875799Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['test_bs']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d787378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T11:15:33.892412Z",
     "iopub.status.busy": "2025-03-10T11:15:33.892117Z",
     "iopub.status.idle": "2025-03-10T11:37:12.641774Z",
     "shell.execute_reply": "2025-03-10T11:37:12.640829Z",
     "shell.execute_reply.started": "2025-03-10T11:15:33.892384Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "best_loss,best_model,_=train_model(config,train_df,val_df)\n",
    "\n",
    "test_dataset=FeedbackPrizeDataset(df_test)\n",
    "test_loader=DataLoader(test_dataset,batch_size=config['test_bs'])\n",
    "\n",
    "model= DebertaModel(config).to(device=config['device'])\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "predictions=[]\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        input_ids=data['input_ids'].to(device=config['device'])\n",
    "        attention_mask=data['attention_mask'].to(device=config['device'])\n",
    "\n",
    "        output=model(input_ids,attention_mask)\n",
    "        predictions.append(output.cpu().numpy())\n",
    "\n",
    "    \n",
    "    predictions=np.concatenate(predictions,axis=0)\n",
    "    df_submission = pd.DataFrame(predictions, columns=config['tcols'])\n",
    "    df_submission.insert(0, 'text_id', df_test['text_id'])\n",
    "\n",
    "    # Load sample submission to ensure format consistency\n",
    "    sample_submission = pd.read_csv(sample_submission_path)\n",
    "    df_submission = df_submission[sample_submission.columns]\n",
    "    \n",
    "    # Save submission file\n",
    "    df_submission.to_csv(base_dir + \"submission.csv\", index=False)\n",
    "    \n",
    "    print(\"Submission file saved at:\", base_dir + \"submission.csv\")\n",
    "    df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 4196674,
     "sourceId": 38321,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 79.425311,
   "end_time": "2025-03-10T13:29:40.180298",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-10T13:28:20.754987",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
